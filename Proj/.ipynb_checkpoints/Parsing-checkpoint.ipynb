{
 "metadata": {
  "name": "",
  "signature": "sha256:6d519c0ef35d3244634a71304aadf1090bb0fa0552948c823ef0885707460b16"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Cover Page"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Project Title**: Visualizing Berkeley's L&S Computer Science Prerequisites\n",
      "\n",
      "**Author**: Zack Garza, December 2014"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Summary"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This document serves as a description of my final project for CS61A, which is to make a graphical visualization of the links and prerequisites between different Computer Science courses at UC Berkeley. The most natural choice was to represent each class as a node on a graph, and link each class to all of its prerequisites. \n",
      "\n",
      "I also decided to write this up using iPython notebook, for several reasons -- one, it makes it very easy to run quick snippets and see their output immediately; two, it's easy to export as a full document; three, it's commonly used in upper division CS courses; and four, it makes it extremely easy to share knowledge and cool code snippets!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "**Motivation**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So why did I choose this project? Well, a few months ago, I saw down and tried to get an idea of what classes I wanted to take in upcoming years. So I pulled down a webpage of common Computer Science courses, pored over the course descriptions, and tried to formulate an opinion on what I could fit in 2-3 years of upper division courses. \n",
      "\n",
      "However, I quickly found out that the complexity of planning out a schedule ramps up very quickly - say you want to take a class on Operating Systems. Alright, not too bad, it's available at most schools to second or third year students. However, in order to take that class, you'll need a class in something like Assembly Language -- but perhaps that class requires taking something like Data Structures, which in turn might require Discrete Math. After spending a few hours trying to keep track of all of these dependencies manually, I figured there *must* be a better solution - we're programmers, after all! Computers were built to solve these kinds of problems.\n",
      "\n",
      "And so the problem that this project aims to solve is this -- finding a way to summarize and quickly trace through class prerequisites to make planning classes easier. I wanted a way to quickly point at a class that looked interesting, and trace it back to its core requirements. I also wanted a way to see the overall structure of the classes. For example, which had the most prerequisites? Which were the most 'valuable', in the sense that they opened the door many other classes? To help answer some of these questions, a graph-like structure seemed like a good place to start, and so this project was born."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Background"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But first things first - we should probably go over what a graph is, and why it makes sense for this kind of visualization. Let's start by looking at a simple graph:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "\n",
      "# By default, images are embedded in notebooks.\n",
      "Image('http://www.eisbox.net/wp-uploads/2009/03/directed-cyclic-graph-425x318.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we have all of the basic features common to graphs - a series of *nodes*, which are usually distinguished from each other by labels, and some number of *edges* connecting the nodes in some fashion. Generally, the edges themselves don't have to necessarily have a direction, but when they do you get a *digraph*, or directed graph.\n",
      "\n",
      "For college classes, a digraph ends up being a good way to model prerequisites - if we let each class be a node, we can connect them with edges that point to its prerequisites and easily trace out a path from any class. As soon as we hit a node that has no arrows coming out of it, we know that we've hit a class with no prerequisites, and that starting there will start the chain of prerequisites leading to whichever class we're interested in."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Operation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So now onto the actual program - how can we code up the idea of classes and prerequisites and make a graph that looks like the image above? To do so requires a few separate steps, so I'll go over them one by one.\n",
      "\n",
      "1. **Get a bunch of raw data about college classes.**\n",
      "\n",
      " Before we can build anything, we need to know about all of the classes and how they are related to  eachother. Fortunately, thanks to the magic of the internet, this information is readily available  to us! We'll use UC Berkeley as a model, since the data is particularly easy to process. \n",
      "\n",
      " Digging around a bit on the Berkeley web site yields the following page:\n",
      " \n",
      " http://general-catalog.berkeley.edu/catalog/gcc_list_crse_req?p_dept_name=Computer+Science&p_dept_cd=COMPSCI&p_path=l\n",
      "\n",
      " Here, we have every class that's listed under the Computer Science major, from freshman to upper  division and even graduate-level courses! And all of the essential information is there - class  names, course codes, and most importantly, lists of prerequisites.\n",
      " \n",
      " So we have the raw data as a giant glob of text, but what can we do with that?\n",
      "\n",
      "2. **Transform the data into something we can work with in Python**.\n",
      "\n",
      " This is the crux of the problem - how can we make sense of that data in the web page? Of course, we can make classes that represent college courses and hold all of their information, but how do we transform that webpage into a bunch of Python objects?\n",
      " \n",
      " Fortunately for us, web pages have a certain amount of structure in them. In particular, this web page has a lot of patterns -- all of the course names are bold, for example, and the word *Prerequisite* is in italics everywhere it is used. Each class is in its own paragraph, and they all have the same format: Course Code, Name, Number of Units, Description, and Prerequisites. \n",
      " \n",
      " With a few libraries to do some of the heavy lifting for us, we can start picking apart this text and extracting the relevant bits with just a bit of work. But okay, assuming we get all of this data, then what?\n",
      " \n",
      "3. **Organize the Data and Build a Graph**\n",
      "\n",
      " Now we just have to make sense of all of these classes and how they're connected. We'll have to simplify our model a bit for now, and just consider the classes within the Computer Science major -- including prerequisites outside of the department (such as a Math requirement) would require repeating this entire process for each other department and linking them all together. Needless to say, this would result in a pretty large graph, adding a lot of noise and complexity, and we're just looking for insight into CS courses for the moment.\n",
      " \n",
      " So we'll get all of these classes, and build a list of prerequisites for each one. We'll call those the \"nodes\", and then go through them and make all of the necessary links as edges. Again, fortunately for us, we have a program and a library that can do most of the heavy lifting for us. So all we really have to do is get all of the data set up for the graphing language and send it on its merry way.\n",
      " \n",
      "4. **Write the Graph as an Image**\n",
      "\n",
      " The last part is by far the easiest - once we have everything in the graphing language, we can call on Python to either write it out to a file for further processing, or use another library to generate the image for us. And then we're done!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Alright, but how does it actually work??\n",
      "We'll go through it step by step!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1: Get a bunch of raw data about college classes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we'll need to import a few libraries:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Used to request web pages over the internet - skip for now\n",
      "# import requests\n",
      "\n",
      "# Parse html into xml trees so we can sift through it more easily\n",
      "from lxml import html\n",
      "\n",
      "# Some extra functions to work with lists.\n",
      "# (Specfically, we'll need to flatten them. We'll come back to this.)\n",
      "import itertools\n",
      "\n",
      "# Perform regex matches\n",
      "import re\n",
      "\n",
      "import os, subprocess\n",
      "from subprocess import Popen, PIPE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we have three essential libraries for parsing all of this data: \n",
      "\n",
      "**lxml** will let us search through html tags and pull out entire chunks of text. For example, we can tell it something like, \"Pull out only the parts of paragraphs that have bold text\", and we would get back a list of (in this case) the course codes and titles, since they're all in bold and in separate paragraphs.\n",
      "\n",
      "**itertools** will just make it easier to work with these lists, which makes the code a bit cleaner and easier to understand.\n",
      "\n",
      "**re** will let us search using *regular expressions* -- these essentially let us search a glob of text for very specific patterns. For example, we know that course codes are always a series of numbers, with maybe a letter or two thrown in. We can make a regular expression that will match only these pieces of text, and collect all of the course codes easily.\n",
      "\n",
      "Now, before we dive into digging through the text, let's define the objects and classes we want to use to hold all of this data. This way, we'll have a better idea of what information we'll need.\n",
      "\n",
      "We'll start by building a \"Department\", like the Computer Science department, that will know all of its classes. It will also take care of holding the \"dotfile\" string, which we'll build later, and will know how to write its dotfile out to a real file so we can visualize it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Represents an entire department and all of its classes.\n",
      "class Department:\n",
      "    \n",
      "    # Holds the 'dotfile' string, which is used to draw the graph.\n",
      "    dotfile = \"\"\n",
      "    \n",
      "    # i.e., \"Mathematics\" or \"Computer Science\"\n",
      "    name = \"Department Name\"\n",
      "    \n",
      "    # Lets us look up class objects by their codes\n",
      "    dept_classes = {}  # Map: \"Class_Code\" -> BerkeleyClass\n",
      "\n",
      "    # A department just needs a name and (maybe) a list of classes \n",
      "    # - classes can always be added later.\n",
      "    def __init__(self, name, initial_list={}):\n",
      "        self.dept_classes = initial_list\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.name\n",
      "\n",
      "    def __repr__(self):\n",
      "        return self.name\n",
      "\n",
      "    # Associate a dotfile string with this department\n",
      "    def set_dotfile(self, string):\n",
      "        self.dotfile = string\n",
      "\n",
      "    # Use this department's dotfile to write out a graph file that is ready to process.\n",
      "    def write_dotfile(self, filename='out.dot'):\n",
      "        if self.dotfile == \"\":\n",
      "            print(\"Dot file must be added with set_dotfile() before writing.\")\n",
      "        else:\n",
      "            with open(filename, 'w') as outfile:\n",
      "                outfile.write(self.dotfile)\n",
      "\n",
      "    # Add a class to this department (as long as it doesn't already exist!)\n",
      "    def add_class(self, new_class):\n",
      "        if new_class not in self.dept_classes:\n",
      "            self.dept_classes.append(new_class)\n",
      "\n",
      "    # Pretty print the classes in this department (useful for debugging or analysis)\n",
      "    def print_classes(self):\n",
      "        for c in self.dept_classes:\n",
      "            print(c)\n",
      "        return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll define a single Class object, which will know it's name, course code, number of units, etc -- essentially, all of the information we saw on the catalog page. We'll simply let each class keep track of its own information this way."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Represents a single class and all of its properties and prerequisites\n",
      "class BerkeleyClass:\n",
      "    \n",
      "    # e.g., \"61A\" or \"181\"\n",
      "    code = \"0000\"\n",
      "    \n",
      "    # The actual name of the class, i.e. \"Compilers\" or \"Operating Systems\"\n",
      "    title = \"default class\"\n",
      "    \n",
      "    # How much credit is given for this class\n",
      "    units = \"(0)\"\n",
      "    \n",
      "    # The catalog description\n",
      "    description = \"default description\"\n",
      "    \n",
      "    # Holds all of the codes of this class's prerequisites\n",
      "    all_prereq_codes = []  # List of strings\n",
      "    \n",
      "    # Holds the prerequisites that are in this class's department\n",
      "    internal_prereqs = []  # List of BerkeleyClass\n",
      "    \n",
      "    # Hold all of the prerequisites outside of this department, possibly for later use\n",
      "    external_prereqs = []  # List of BerkeleyClass\n",
      "\n",
      "    # A class needs all of these things, since we'll want this information later.\n",
      "    def __init__(self, code, title, units):\n",
      "        self.code = code.encode('utf-8')\n",
      "        self.title = title\n",
      "        self.units = units\n",
      "        \n",
      "        # Deals with weird member variable construction bug in python\n",
      "        self.all_prereq_codes = []\n",
      "        \n",
      "    def add_prereq(self, prereq_code):\n",
      "        self.all_prereq_codes.append(prereq_code.encode('utf-8'))\n",
      "\n",
      "    # Pretty print this class's information\n",
      "    def __str__(self):\n",
      "        return \"---------------------------------------\" + '\\n' + \\\n",
      "            \"Class: \" + self.title + '\\n' + \\\n",
      "            \"Code: \" + str(self.code) + '\\n' + \\\n",
      "            \"CS Prereqs: \" + str(self.internal_prereqs) + '\\n' + \\\n",
      "            \"External prereqs: \" + str(self.external_prereqs) + \"\\n\" +\\\n",
      "            \"---------------------------------------\" + '\\n'\n",
      "\n",
      "    def __repr__(self):\n",
      "        return self.__str__()\n",
      "\n",
      "    # For most purposes, we'll say two classes are the same if their codes are the same\n",
      "    def __eq__(self, other_class):\n",
      "        return self.code == other_class.code"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2: Transform the data into something we can work with in Python.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we'll dive into actually digging through the text of this page.\n",
      "\n",
      "For now, we'll skip requesting page via HTTP, and simply save the file and read it in from the disk for now."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get html file from url\n",
      "# page = requests.get('http://general-catalog.berkeley.edu/catalog/gcc_list_crse_req?p_dept_name=Computer+Science&p_dept_cd=COMPSCI&p_path=l')\n",
      "# tree = html.fromstring(page.text)\n",
      "\n",
      "with open(\"file.html\", \"r\") as myfile:\n",
      "    page = myfile.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we'll convert the blob of text into a document tree so we can search it easily.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree = html.fromstring(page)\n",
      "print tree.head.text_content()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, pull out all of the paragraph blocks - each block contains a class description."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blocks = tree.xpath('/html/body/table[3]/tbody/tr/td[2]/font/p')\n",
      "blocks[0].text_content()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll pause here for a moment -- how did we know which 'xpath' to put in to find what we were looking for?\n",
      "\n",
      "In most browsers, you can actually open a web inspector/debug tool, navigate to the element you're interested in -- in our case, a paragraph with information about a class -- and use the \"Copy XPath\" option to get something to start with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image('xpath_screen.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Grabbing that XPath yields\n",
      "```python\n",
      "/html/body/table[3]/tbody/tr/td[2]/font/p[2]\n",
      "```\n",
      "\n",
      "But wait! In the code above, we had\n",
      "```python\n",
      "/html/body/table[3]/tbody/tr/td[2]/font/p\n",
      "```\n",
      "\n",
      "Why should the **p** element at the end be any different? The answer is that copying it from the browser yielding the path of one *single* paragraph -- specifically, the second one that occurred at that tree path (compare the XPath to the tree shown in the picture to see why this is).\n",
      "\n",
      "What we actually want is *all* of the paragraphs, so we just leave the number parameter blank. In Python terms, this is like getting an entire list instead of just one element from it.\n",
      "\n",
      "Alright, so now that we have some paragraph blocks, onward ho!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll filter out the blocks *without* prerequisites - this just\n",
      "gets rid of extra blocks that don't contain a\n",
      "class description like classes without prereqs that have the\n",
      "text \"Prerequisite: None\" or something similar."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prereq_blocks = [b for b in blocks if \"Prereq\" in b.text_content()]\n",
      "print prereq_blocks[1].text_content()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since there's only one **b** tag per block, and it contains\n",
      "all the info we need, we'll grab all the **b** blocks:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles = [b.xpath('b') for b in prereq_blocks]\n",
      "titles[0:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this, we see that our list is actually a list of lists, which can get pretty confusing. For this, we'll make use **itertools**, which we imported earlier, to just flatten this into a single list and make our lives a bit easier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merged_titles = list(itertools.chain.from_iterable(titles))\n",
      "merged_titles[0:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll tackle getting the Prerequisites. They're located inside of **i** tages, but a block may have one or two of these. So, we'll get all of the **i** nodes first, then keep only those that have the word \"Prerequisite\" in them"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a list to hold all of the actual prerequisites.\n",
      "prereqs = []\n",
      "\n",
      "# Get all of the italics nodes\n",
      "possible_prereq_chunks = [b.xpath('i') for b in prereq_blocks]\n",
      "\n",
      "# Then, keep only the <i> blocks that contain the word \"Prerequisite\"\n",
      "for p in possible_prereq_chunks:\n",
      "    for p2 in p:\n",
      "        if \"Prerequisite\" in p2.text_content():\n",
      "            prereqs.append(p2)\n",
      "\n",
      "# Now, there should be one blob of prerequisites for each\n",
      "# and every class that we found.\n",
      "assert(len(prereqs) == len(merged_titles))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Alright! Now we have all of the information we need."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3: Organize the Data and Build a Graph"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll start by associating each class title with the big blob of Prerequisite text we just got."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Maps course titles to Prereq blobs\n",
      "dict = {}  #String => String\n",
      "\n",
      "for i in range(0, len(merged_titles)):\n",
      "    dict[merged_titles[i].text_content()] = prereqs[i].text_content()\n",
      "\n",
      "example = [d for d in dict][1]\n",
      "print example, \"\\n ====> \\n\", dict[example]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll move on to actually parsing each class's info.\n",
      "\n",
      "We'll start by defining a function that separates out the relevant text:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_class_text(title_string, prereq_string):\n",
      "    code, title, units = title_string.split('.')\n",
      "    raw_prereqs = re.findall('\\d+[A-Z]*', prereq_string)\n",
      "    prereqs = [p.encode('utf-8') for p in raw_prereqs]\n",
      "    \n",
      "    return code.encode('utf-8'), title.encode('utf-8'), units.encode('utf-8'), prereqs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You'll notice here that we used the **re** library we imported early. The string ```\"\\d+[A-Z]*\"``` is a regex pattern, where **\\\\d+** searches for one or more number at the start of the string, and **[A-Z]\\* ** allows for 0 or more valid letters.\n",
      "\n",
      "Next we'll create a map that lets us look up a class by its course code, and then use the function we just made to make class objects to populate it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class_codes = {}  # String => BerkeleyClass\n",
      "\n",
      "# Populate class code lookup table\n",
      "for d in dict.keys():\n",
      "    code, title, units, prereq_codes = parse_class_text(d, dict[d])\n",
      "    this_class = BerkeleyClass(code, title, units)\n",
      "    for p in prereq_codes:\n",
      "        this_class.add_prereq(p)\n",
      "    class_codes[code.encode('utf-8')] = this_class\n",
      "\n",
      "print \"Sample Class Codes Found:\"\n",
      "print class_codes.values()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll populate the prerequisite list for each class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cs61a = class_codes[\"61A\"]\n",
      "print cs61a\n",
      "print cs61a.all_prereq_codes\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for this_class in class_codes.values():\n",
      "\n",
      "    # Counteracts weird bug that picks up prereqs from list iterated class\n",
      "    this_class.internal_prereqs = []\n",
      "    this_class.external_prereqs = []\n",
      "    unknown_prereqs = []\n",
      "\n",
      "    # Double check that these variables are empty\n",
      "    assert(len(unknown_prereqs) == 0)\n",
      "    assert(len(this_class.internal_prereqs) == 0)\n",
      "\n",
      "    # Add all of the known classes (within department) to prereqs\n",
      "    for s in this_class.all_prereq_codes:\n",
      "        if s in class_codes.keys():\n",
      "            this_class.add_prereq(s)\n",
      "\n",
      "    # Make a list of all prereqs that weren't found in the lookup table\n",
      "    unknown_prereqs = [l for l in this_class.all_prereq_codes\n",
      "                       if l not in this_class.internal_prereqs]\n",
      "\n",
      "    # Make sure no classes were lost\n",
      "    assert(len(this_class.internal_prereqs) + len(unknown_prereqs)\n",
      "           == len(this_class.all_prereq_codes))\n",
      "\n",
      "    # Keep track of all of the classes that weren't found\n",
      "    this_class.external_prereqs = [u for u in unknown_prereqs]\n",
      "    \n",
      "print(class_codes[\"61A\"].__str__())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So now our dictionary of course codes to Berkeley Classes is full, and each class has information about itself. Now we can move on to actually building the graph!\n",
      "\n",
      "Note - normally, this would be done by importing a library and using their methods for building nodes and edges. Unfortunately, the library is a bit buggy, so instead we're simply going to write the raw file that represents the graph ourselves as a string, and run the program manually (essentially doing what the library would have done under the hood)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We start by making 3 different categories where we can store classes. This way, we can sort classes different based on what level they are, and hopefully gain some more insight. We'll also make corresponding strings that we'll mix in to the final mega-string that represents the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lower, upper, grad = [], [], []\n",
      "l_class_strs, u_class_strs, g_class_strs = [], [], []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll write out the file header with some custom attributes -- namely, to make the graph extremely large, and to space the nodes out quite a bit."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Start building string that will go into the dotfile\n",
      "prefix = \"digraph g {\\n\"\\\n",
      "    + \"ratio=fill;\\n\"\\\n",
      "    + \"graph [ size = \\\"25,25\\\", ranksep=5 ];\"\n",
      "    \n",
      "print prefix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll go through all of the classes we have, look at all of that class's prerequisites, and build a link between that class and each prerequisite. This will correspond to an edge on the graph, so we'll put together the string that programs that relationship as well, and sort them into the categories we defined earlier so we can keep track of what goes where."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build the edge list\n",
      "for c in class_codes.values():\n",
      "\n",
      "    # Since these variable are being reused, make sure they're empty\n",
      "    node = []\n",
      "    strs = []\n",
      "    assert(len(node) == 0)\n",
      "\n",
      "    # First, sort out the upper/lower divs and grad classes\n",
      "    \n",
      "    # Start by looking at the first character - is it a number?\n",
      "    \n",
      "    if c.code[0] == '2':\n",
      "        # Graduate Class\n",
      "        node = grad\n",
      "        strs = g_class_strs\n",
      "        \n",
      "    elif c.code[0] == '1':\n",
      "        # Upper Division Class\n",
      "        node = upper\n",
      "        strs = u_class_strs\n",
      "\n",
      "    # Is it an alternate version of a normal course?\n",
      "    elif c.code[0].isalpha():\n",
      "        \n",
      "        if c.code[1] == '2':\n",
      "            # Alternate Version Graduate\n",
      "            node = grad\n",
      "            strs = g_class_strs\n",
      "            \n",
      "        elif c.code[1] == '1':\n",
      "            # Alternate Version Upper-Div\n",
      "            node = upper\n",
      "            strs = u_class_strs\n",
      "            \n",
      "        else:\n",
      "            # Alternate Version Lower-Div\n",
      "            node = lower\n",
      "            strs = l_class_strs\n",
      "            \n",
      "    else:\n",
      "        # It must be a normal lower division class otherwise\n",
      "        node = lower\n",
      "        strs = l_class_strs\n",
      "\n",
      "    # Sort this class into the appropriate category\n",
      "    if c.internal_prereqs != []:\n",
      "        if c.code not in strs:\n",
      "            strs.append(c.code)\n",
      "\n",
      "    # Create the string the will represent this class's prerequisite\n",
      "    # relationships as edges between nodes\n",
      "    for p_code in c.internal_prereqs:\n",
      "        \n",
      "        node_str = \"  \\\"\" + str(c.code) + \"\\\" -> \\\"\" + str(p_code) + \"\\\";\"\n",
      "        node.append(node_str)\n",
      "        node_str = \"\"\n",
      "        \n",
      "print \"Example: Lower Division: \\n\", l_class_strs, '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we'll remove the duplicates from each of the categories we created by making a mathematical set out of each of them. This is just to prevent waste, as the graphing software is smart enough to only plot one if there are multiple identical nodes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l_class_strs_set = set(l_class_strs)\n",
      "u_class_strs_set = set(u_class_strs)\n",
      "g_class_strs_set = set(g_class_strs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To help us see the relationships between classes, we'll set the graph to line up all lower division classes together, as well as upper-division and graduate classes respectively. We accomplish this by \"ranking\" all of each category at the same level."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# String building:\n",
      "l_rank_equalizer = \"{ rank=same; \"\n",
      "for l in l_class_strs_set:\n",
      "    l_rank_equalizer += \"\\\"\" + l + \"\\\"; \"\n",
      "l_rank_equalizer += \"}\\n\"\n",
      "\n",
      "u_rank_equalizer = \"{ rank=same; \"\n",
      "for u in u_class_strs_set:\n",
      "    u_rank_equalizer += \"\\\"\" + u + \"\\\"; \"\n",
      "u_rank_equalizer += \"}\\n\"\n",
      "\n",
      "g_rank_equalizer = \"{ rank=same; \"\n",
      "for g in g_class_strs_set:\n",
      "    g_rank_equalizer += \"\\\"\" + g + \"\\\"; \"\n",
      "g_rank_equalizer += \"}\\n\"\n",
      "\n",
      "print l_rank_equalizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll add in all of the edges we built earlier, each separated by a newline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lower_cluster = \"\\n\".join(lower) + \"\\n\"\n",
      "upper_cluster = \"\\n\".join(upper) + \"\\n\"\n",
      "grad_cluster = \"\\n\".join(grad) + \"\\n\"\n",
      "postfix = \"\\n}\"\n",
      "\n",
      "print lower_cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have the file header prefix, the clauses that equalize the rank of each category, and the actual edges themselves, so now we'll combine them all into one large string -- this will be our dotfile."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Concatenate all the substrings into the final dot file representation\n",
      "final = prefix + \\\n",
      "    l_rank_equalizer + lower_cluster + \\\n",
      "    u_rank_equalizer + upper_cluster + \\\n",
      "    g_rank_equalizer + grad_cluster + \\\n",
      "    postfix\n",
      "\n",
      "print final"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll associate that dotfile with a department -- remember, each department has methods for holding and writing out a dotfile, so we can use it to write our final file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "computerScienceDept = Department(\"Computer Science\", class_codes)\n",
      "computerScienceDept.set_dotfile(final)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now all that's left to do is write the file and process it with the graphing software - the syntax is just\n",
      "\n",
      "```\n",
      "dot -T png -o output_graph.png ./out.dot\n",
      "```\n",
      "\n",
      "where ```output_graph.png``` is the name of the image to output, and ```out.dot``` is the dotfile that we'll write. There are several algorithms that can be experimented with; the default is shown below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dot_file_name = \"out2.dot\"\n",
      "graph_file_name = \"output_graph.png\"\n",
      "\n",
      "computerScienceDept.write_dotfile(filename=dot_file_name)\n",
      "\n",
      "process = Popen(['dot', '-Tpng', '-o', graph_file_name, dot_file_name])\n",
      "exit_code = process.wait()\n",
      "\n",
      "Image(graph_file_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And that's all there is to it! Here are a few insights we can glean from the graph:\n",
      "\n",
      "1. Almost every class requires taking 61A at some point.\n",
      "\n",
      "2. In fact, the 61 series are the \"gateway\" classes into most upper division classes.\n",
      "\n",
      "3. In particular, CS70 feeds into a wide variety of classes.\n",
      "\n",
      "4. Most graduate-level courses directly build off of upper division classes, and can be taken in isolation. Notable exceptions are 262, 264, 286, and 271."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c in class_codes.values():\n",
      "    print c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}